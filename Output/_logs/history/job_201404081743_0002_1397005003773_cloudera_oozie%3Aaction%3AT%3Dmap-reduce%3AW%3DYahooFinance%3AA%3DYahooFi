Meta VERSION="1" .
Job JOBID="job_201404081743_0002" JOBNAME="oozie:action:T\=map-reduce:W\=YahooFinance:A\=YahooFinance:ID\=0000000-140408174400521-oozie-oozi-W" USER="cloudera" SUBMIT_TIME="1397005003773" JOBCONF="hdfs://localhost\.localdomain:8020/user/cloudera/\.staging/job_201404081743_0002/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201404081743_0002" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201404081743_0002" LAUNCH_TIME="1397005004264" TOTAL_MAPS="2" TOTAL_REDUCES="1" JOB_STATUS="PREP" .
Task TASKID="task_201404081743_0002_m_000003" TASK_TYPE="SETUP" START_TIME="1397005004300" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201404081743_0002_m_000003" TASK_ATTEMPT_ID="attempt_201404081743_0002_m_000003_0" START_TIME="1397005004520" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58532" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201404081743_0002_m_000003" TASK_ATTEMPT_ID="attempt_201404081743_0002_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1397005011094" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(165998)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(80)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(90505216)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(652943360)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201404081743_0002_m_000003" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1397005011280" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(165998)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(80)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(90505216)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(652943360)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201404081743_0002" JOB_STATUS="RUNNING" .
Task TASKID="task_201404081743_0002_m_000000" TASK_TYPE="MAP" START_TIME="1397005012226" SPLITS="/default/localhost\.localdomain" .
Task TASKID="task_201404081743_0002_m_000001" TASK_TYPE="MAP" START_TIME="1397005012226" SPLITS="/default/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201404081743_0002_m_000000" TASK_ATTEMPT_ID="attempt_201404081743_0002_m_000000_0" START_TIME="1397005012231" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58532" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201404081743_0002_m_000000" TASK_ATTEMPT_ID="attempt_201404081743_0002_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1397005020027" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="hdfs://localhost\.localdomain:8020/yahoofile:915+916" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(166331)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(1012)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(15)][(MAP_OUTPUT_RECORDS)(Map output records)(15)][(MAP_OUTPUT_BYTES)(Map output bytes)(463)][(SPLIT_RAW_BYTES)(Input split bytes)(96)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(15)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(430)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(145887232)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(661475328)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(890)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201404081743_0002_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1397005020105" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(166331)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(1012)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(15)][(MAP_OUTPUT_RECORDS)(Map output records)(15)][(MAP_OUTPUT_BYTES)(Map output bytes)(463)][(SPLIT_RAW_BYTES)(Input split bytes)(96)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(15)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(430)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(145887232)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(661475328)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(890)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201404081743_0002_m_000001" TASK_ATTEMPT_ID="attempt_201404081743_0002_m_000001_0" START_TIME="1397005012236" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58532" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201404081743_0002_m_000001" TASK_ATTEMPT_ID="attempt_201404081743_0002_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1397005020001" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="hdfs://localhost\.localdomain:8020/yahoofile:0+915" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(166332)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(1927)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(16)][(MAP_OUTPUT_RECORDS)(Map output records)(16)][(MAP_OUTPUT_BYTES)(Map output bytes)(491)][(SPLIT_RAW_BYTES)(Input split bytes)(96)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(16)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(430)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(144588800)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(661475328)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(941)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201404081743_0002_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1397005020107" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(166332)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(1927)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(16)][(MAP_OUTPUT_RECORDS)(Map output records)(16)][(MAP_OUTPUT_BYTES)(Map output bytes)(491)][(SPLIT_RAW_BYTES)(Input split bytes)(96)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(16)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(430)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(144588800)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(661475328)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(941)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201404081743_0002_r_000000" TASK_TYPE="REDUCE" START_TIME="1397005022231" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201404081743_0002_r_000000" TASK_ATTEMPT_ID="attempt_201404081743_0002_r_000000_0" START_TIME="1397005022246" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58532" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201404081743_0002_r_000000" TASK_ATTEMPT_ID="attempt_201404081743_0002_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1397005025695" SORT_FINISHED="1397005025734" FINISH_TIME="1397005027211" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(551)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(166260)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(78)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(2)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(603)][(REDUCE_INPUT_RECORDS)(Reduce input records)(31)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(4)][(SPILLED_RECORDS)(Spilled Records)(31)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(760)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(97337344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(674119680)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201404081743_0002_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1397005027387" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(551)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(166260)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(78)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(2)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(603)][(REDUCE_INPUT_RECORDS)(Reduce input records)(31)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(4)][(SPILLED_RECORDS)(Spilled Records)(31)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(760)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(97337344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(674119680)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201404081743_0002_m_000002" TASK_TYPE="CLEANUP" START_TIME="1397005027389" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201404081743_0002_m_000002" TASK_ATTEMPT_ID="attempt_201404081743_0002_m_000002_0" START_TIME="1397005027395" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58532" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201404081743_0002_m_000002" TASK_ATTEMPT_ID="attempt_201404081743_0002_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1397005030849" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(165998)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(130)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(89157632)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(653996032)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201404081743_0002_m_000002" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1397005031029" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(165998)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(130)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(89157632)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(653996032)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201404081743_0002" FINISH_TIME="1397005031033" JOB_STATUS="SUCCESS" FINISHED_MAPS="2" FINISHED_REDUCES="1" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(332663)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(2939)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(4)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(31)][(MAP_OUTPUT_RECORDS)(Map output records)(31)][(MAP_OUTPUT_BYTES)(Map output bytes)(954)][(SPLIT_RAW_BYTES)(Input split bytes)(192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(31)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(860)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(290476032)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(1322950656)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(221126656)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(1831)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(551)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(166260)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(78)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(2)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(603)][(REDUCE_INPUT_RECORDS)(Reduce input records)(31)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(4)][(SPILLED_RECORDS)(Spilled Records)(31)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(760)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(97337344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(674119680)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(551)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(498923)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(2939)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(78)][(HDFS_READ_OPS)(HDFS: Number of read operations)(5)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.JobCounter)(Job Counters )[(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(2)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(1)][(DATA_LOCAL_MAPS)(Data-local map tasks)(2)][(SLOTS_MILLIS_MAPS)(Total time spent by all maps in occupied slots \\(ms\\))(25589)][(SLOTS_MILLIS_REDUCES)(Total time spent by all reduces in occupied slots \\(ms\\))(4965)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(31)][(MAP_OUTPUT_RECORDS)(Map output records)(31)][(MAP_OUTPUT_BYTES)(Map output bytes)(954)][(SPLIT_RAW_BYTES)(Input split bytes)(192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(2)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(603)][(REDUCE_INPUT_RECORDS)(Reduce input records)(31)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(4)][(SPILLED_RECORDS)(Spilled Records)(62)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1620)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(387813376)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(1997070336)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(281878528)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(1831)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
